{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open3d\n",
      "  Using cached open3d-0.19.0-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting numpy>=1.18.0 (from open3d)\n",
      "  Using cached numpy-2.2.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting dash>=2.6.0 (from open3d)\n",
      "  Using cached dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting werkzeug>=3.0.0 (from open3d)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting flask>=3.0.0 (from open3d)\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting nbformat>=5.7.0 (from open3d)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting configargparse (from open3d)\n",
      "  Using cached ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ipywidgets>=8.0.4 (from open3d)\n",
      "  Using cached ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting flask>=3.0.0 (from open3d)\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting werkzeug>=3.0.0 (from open3d)\n",
      "  Using cached werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting plotly>=5.0.0 (from dash>=2.6.0->open3d)\n",
      "  Using cached plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
      "  Using cached dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
      "  Using cached dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
      "  Using cached dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting importlib-metadata (from dash>=2.6.0->open3d)\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typing-extensions>=4.1.1 (from dash>=2.6.0->open3d)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting requests (from dash>=2.6.0->open3d)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting retrying (from dash>=2.6.0->open3d)\n",
      "  Using cached retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
      "Collecting setuptools (from dash>=2.6.0->open3d)\n",
      "  Using cached setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting Jinja2>=3.1.2 (from flask>=3.0.0->open3d)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting itsdangerous>=2.1.2 (from flask>=3.0.0->open3d)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from flask>=3.0.0->open3d)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting blinker>=1.6.2 (from flask>=3.0.0->open3d)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->open3d)\n",
      "  Using cached widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets>=8.0.4->open3d)\n",
      "  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7.0->open3d)\n",
      "  Using cached fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat>=5.7.0->open3d)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=3.0.0->open3d)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: colorama in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from click>=8.1.3->flask>=3.0.0->open3d) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.6.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat>=5.7.0->open3d)\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat>=5.7.0->open3d)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat>=5.7.0->open3d)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat>=5.7.0->open3d)\n",
      "  Using cached rpds_py-0.23.1-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (309)\n",
      "Collecting narwhals>=1.15.1 (from plotly>=5.0.0->dash>=2.6.0->open3d)\n",
      "  Using cached narwhals-1.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (24.2)\n",
      "Collecting zipp>=3.20 (from importlib-metadata->dash>=2.6.0->open3d)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->dash>=2.6.0->open3d)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->dash>=2.6.0->open3d)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->dash>=2.6.0->open3d)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->dash>=2.6.0->open3d)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: six>=1.7.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from retrying->dash>=2.6.0->open3d) (1.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.3)\n",
      "Using cached open3d-0.19.0-cp312-cp312-win_amd64.whl (69.2 MB)\n",
      "Using cached dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
      "Using cached dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Using cached dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Using cached dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached numpy-2.2.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Using cached ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Using cached setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached narwhals-1.29.1-py3-none-any.whl (308 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.23.1-cp312-cp312-win_amd64.whl (237 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: fastjsonschema, dash-table, dash-html-components, dash-core-components, zipp, widgetsnbextension, urllib3, typing-extensions, setuptools, rpds-py, retrying, numpy, narwhals, MarkupSafe, jupyterlab-widgets, itsdangerous, idna, configargparse, click, charset-normalizer, certifi, blinker, attrs, werkzeug, requests, referencing, plotly, Jinja2, importlib-metadata, jsonschema-specifications, ipywidgets, flask, jsonschema, dash, nbformat, open3d\n",
      "Successfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 attrs-25.1.0 blinker-1.9.0 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 configargparse-1.7 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 fastjsonschema-2.21.1 flask-3.0.3 idna-3.10 importlib-metadata-8.6.1 ipywidgets-8.1.5 itsdangerous-2.2.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyterlab-widgets-3.0.13 narwhals-1.29.1 nbformat-5.10.4 numpy-2.2.3 open3d-0.19.0 plotly-6.0.0 referencing-0.36.2 requests-2.32.3 retrying-1.3.4 rpds-py-0.23.1 setuptools-76.0.0 typing-extensions-4.12.2 urllib3-2.3.0 werkzeug-3.0.6 widgetsnbextension-4.0.13 zipp-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytorch networkx matplotlib numpy scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: networkx\n",
      "Successfully installed networkx-3.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trimesh\n",
      "  Using cached trimesh-4.6.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from trimesh) (2.2.3)\n",
      "Using cached trimesh-4.6.4-py3-none-any.whl (708 kB)\n",
      "Installing collected packages: trimesh\n",
      "Successfully installed trimesh-4.6.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rtree\n",
      "  Using cached rtree-1.4.0-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Using cached rtree-1.4.0-py3-none-win_amd64.whl (385 kB)\n",
      "Installing collected packages: rtree\n",
      "Successfully installed rtree-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Using cached shapely-2.0.7-cp312-cp312-win_amd64.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from shapely) (2.2.3)\n",
      "Using cached shapely-2.0.7-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "Installing collected packages: shapely\n",
      "Successfully installed shapely-2.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.56.0-cp312-cp312-win_amd64.whl.metadata (103 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.1-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.56.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.1.0 pyparsing-3.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.dgl.ai/wheels/cu124/repo.html\n",
      "Collecting dgl\n",
      "  Downloading dgl-2.2.1-cp312-cp312-win_amd64.whl.metadata (595 bytes)\n",
      "Requirement already satisfied: numpy>=1.14.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from dgl) (2.2.3)\n",
      "Collecting scipy>=1.1.0 (from dgl)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: networkx>=2.1 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from dgl) (3.4.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from dgl) (2.32.3)\n",
      "Collecting tqdm (from dgl)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil>=5.8.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from dgl) (7.0.0)\n",
      "Collecting torchdata>=0.5.0 (from dgl)\n",
      "  Downloading torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pandas (from dgl)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from requests>=2.19.0->dgl) (2025.1.31)\n",
      "Collecting torch>=2 (from torchdata>=0.5.0->dgl)\n",
      "  Using cached torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from pandas->dgl) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->dgl)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->dgl)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from tqdm->dgl) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n",
      "Collecting filelock (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.6)\n",
      "Collecting fsspec (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (76.0.0)\n",
      "Collecting sympy==1.13.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\iaac\\research\\github\\octopusie\\.venv\\lib\\site-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (3.0.2)\n",
      "Downloading dgl-2.2.1-cp312-cp312-win_amd64.whl (5.3 MB)\n",
      "   ---------------------------------------- 0.0/5.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.1/5.3 MB 14.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.5/5.3 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.3/5.3 MB 11.6 MB/s eta 0:00:00\n",
      "Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "Downloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: pytz, mpmath, tzdata, tqdm, sympy, scipy, fsspec, filelock, torch, pandas, torchdata, dgl\n",
      "Successfully installed dgl-2.2.1 filelock-3.17.0 fsspec-2025.3.0 mpmath-1.3.0 pandas-2.2.3 pytz-2025.1 scipy-1.15.2 sympy-1.13.1 torch-2.6.0 torchdata-0.11.0 tqdm-4.67.1 tzdata-2025.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  dgl -f https://data.dgl.ai/wheels/cu124/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing floors in the model: 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExisting floors in the model:\u001b[39m\u001b[33m\"\u001b[39m, existing_floors_count)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# 3. Combine Existing Floors with User Input\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m additional_floors = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEnter the additional number of floors to add: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m total_floors = existing_floors_count + additional_floors\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTotal floors for new analysis:\u001b[39m\u001b[33m\"\u001b[39m, total_floors)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load the OBJ Model\n",
    "# ----------------------------\n",
    "obj_path =  r\"..\\Reference Files\\Geometry 1.obj\"  # Replace with your OBJ file path\n",
    "mesh = trimesh.load(obj_path)\n",
    "vertices = mesh.vertices\n",
    "faces = mesh.faces\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Calculate Existing and New Floors\n",
    "# ----------------------------\n",
    "def is_floor(face_normal, normal_threshold=0.1):\n",
    "    \"\"\"Determine if a face is horizontal enough to be considered a floor.\"\"\"\n",
    "    return abs(face_normal[2]) > (1 - normal_threshold)\n",
    "\n",
    "def group_connected_faces(face_indices, normals, mesh_object, similarity_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Group face indices based on connectivity and similar normals.\n",
    "    Uses mesh_object.face_adjacency for connectivity.\n",
    "    \"\"\"\n",
    "    groups = []\n",
    "    visited = set()\n",
    "    for face_index in face_indices:\n",
    "        if face_index in visited:\n",
    "            continue\n",
    "        group = {face_index}\n",
    "        queue = [face_index]\n",
    "        visited.add(face_index)\n",
    "        while queue:\n",
    "            current = queue.pop(0)\n",
    "            # Gather neighbors from face_adjacency\n",
    "            neighbors = set()\n",
    "            for pair in mesh_object.face_adjacency:\n",
    "                if current in pair:\n",
    "                    neighbors.update(pair)\n",
    "            neighbors.discard(current)\n",
    "            for neighbor in neighbors:\n",
    "                if neighbor in visited:\n",
    "                    continue\n",
    "                # Compare normals using dot product\n",
    "                if np.dot(normals[current], normals[neighbor]) > similarity_threshold:\n",
    "                    group.add(neighbor)\n",
    "                    queue.append(neighbor)\n",
    "                    visited.add(neighbor)\n",
    "        groups.append(list(group))\n",
    "    return groups\n",
    "\n",
    "all_face_indices = set(range(len(faces)))\n",
    "existing_floor_face_indices = [i for i in all_face_indices if is_floor(mesh.face_normals[i])]\n",
    "existing_floor_groups = group_connected_faces(existing_floor_face_indices, mesh.face_normals, mesh)\n",
    "existing_floors_count = len(existing_floor_groups)\n",
    "print(\"Existing floors in the model:\", existing_floors_count)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Combine Existing Floors with User Input\n",
    "# ----------------------------\n",
    "additional_floors = int(input(\"Enter the additional number of floors to add: \"))\n",
    "total_floors = existing_floors_count + additional_floors\n",
    "print(\"Total floors for new analysis:\", total_floors)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Divide the Model Vertically Based on Total Floors\n",
    "# ----------------------------\n",
    "def divide_into_floors(vertices, num_floors):\n",
    "    \"\"\"Compute equally spaced floor levels along Z using the model's bounding box.\"\"\"\n",
    "    min_z = np.min(vertices[:, 2])\n",
    "    max_z = np.max(vertices[:, 2])\n",
    "    floor_height = (max_z - min_z) / num_floors\n",
    "    floor_levels = [min_z + i * floor_height for i in range(num_floors + 1)]\n",
    "    return floor_levels\n",
    "\n",
    "floor_levels = divide_into_floors(vertices, total_floors)\n",
    "print(\"Calculated Floor Levels:\", floor_levels)\n",
    "\n",
    "# Detect floors with height less than 3 meters\n",
    "low_floor_detected = False\n",
    "for i in range(1, len(floor_levels)):\n",
    "    floor_height = floor_levels[i] - floor_levels[i - 1]\n",
    "    if floor_height < 3.0:\n",
    "        print(f\"Warning: Floor with height = {floor_height:.2f} meters detected.\")\n",
    "        low_floor_detected = True\n",
    "\n",
    "if not low_floor_detected:\n",
    "    print(\"All floors are over 3 meters.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Create New Sliced Meshes for Floors and Walls\n",
    "# ----------------------------\n",
    "def create_sliced_mesh(vertices, faces, floor_levels, original_mesh, normal_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Classify each face as floor (if horizontal) or wall (if vertical) based on its centroid's Z.\n",
    "    Returns lists of face indices for floors and walls.\n",
    "    \"\"\"\n",
    "    floor_face_indices = []\n",
    "    wall_face_indices = []\n",
    "    for i, face in enumerate(faces):\n",
    "        pts = vertices[face]\n",
    "        centroid = pts.mean(axis=0)\n",
    "        face_normal = original_mesh.face_normals[i]\n",
    "        assigned = False\n",
    "        if is_floor(face_normal, normal_threshold):\n",
    "            # Assign to a floor slice based on the centroid\n",
    "            for j in range(len(floor_levels) - 1):\n",
    "                if floor_levels[j] <= centroid[2] < floor_levels[j+1]:\n",
    "                    floor_face_indices.append(i)\n",
    "                    assigned = True\n",
    "                    break\n",
    "        # If not a floor and clearly vertical, assign as wall.\n",
    "        if not assigned and (abs(face_normal[2]) < normal_threshold):\n",
    "            wall_face_indices.append(i)\n",
    "    return floor_face_indices, wall_face_indices\n",
    "\n",
    "floor_face_indices_new, wall_face_indices_new = create_sliced_mesh(vertices, faces, floor_levels, mesh)\n",
    "\n",
    "# Create new trimesh objects from the selected faces.\n",
    "if len(floor_face_indices_new) > 0:\n",
    "    floor_mesh_new = trimesh.Trimesh(vertices=vertices, faces=faces[floor_face_indices_new], process=True)\n",
    "else:\n",
    "    floor_mesh_new = None\n",
    "\n",
    "if len(wall_face_indices_new) > 0:\n",
    "    wall_mesh_new = trimesh.Trimesh(vertices=vertices, faces=faces[wall_face_indices_new], process=True)\n",
    "else:\n",
    "    wall_mesh_new = None\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Group Connected Faces on the New Meshes\n",
    "# ----------------------------\n",
    "if floor_mesh_new is not None:\n",
    "    floor_normals_new = floor_mesh_new.face_normals\n",
    "    floor_face_ids = list(range(len(floor_mesh_new.faces)))\n",
    "    floor_groups_new = group_connected_faces(floor_face_ids, floor_normals_new, floor_mesh_new)\n",
    "else:\n",
    "    floor_groups_new = []\n",
    "\n",
    "if wall_mesh_new is not None:\n",
    "    wall_normals_new = wall_mesh_new.face_normals\n",
    "    wall_face_ids = list(range(len(wall_mesh_new.faces)))\n",
    "    wall_groups_new = group_connected_faces(wall_face_ids, wall_normals_new, wall_mesh_new)\n",
    "else:\n",
    "    wall_groups_new = []\n",
    "\n",
    "num_floors_new = len(floor_groups_new)\n",
    "num_walls_new = len(wall_groups_new)\n",
    "print(f\"Number of floor groups in new mesh: {num_floors_new}\")\n",
    "print(f\"Number of wall groups in new mesh: {num_walls_new}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Visualization Using Plotly\n",
    "# ----------------------------\n",
    "def visualize_floors(vertices, faces, floor_levels):\n",
    "    \"\"\"\n",
    "    Visualize the base model and semi-transparent horizontal surfaces for each calculated floor level.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Base model mesh (low opacity)\n",
    "    fig.add_trace(go.Mesh3d(x=vertices[:, 0],\n",
    "                            y=vertices[:, 1],\n",
    "                            z=vertices[:, 2],\n",
    "                            i=faces[:, 0],\n",
    "                            j=faces[:, 1],\n",
    "                            k=faces[:, 2],\n",
    "                            opacity=0.1,\n",
    "                            color='red'))\n",
    "    \n",
    "    # Create horizontal grid surfaces for each floor level\n",
    "    x_min, x_max = np.min(vertices[:, 0]), np.max(vertices[:, 0])\n",
    "    y_min, y_max = np.min(vertices[:, 1]), np.max(vertices[:, 1])\n",
    "    \n",
    "    for i in range(len(floor_levels) - 1):\n",
    "        z_level = floor_levels[i]\n",
    "        x = np.linspace(x_min, x_max, 250)\n",
    "        y = np.linspace(y_min, y_max, 250)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.full_like(X, z_level)\n",
    "        \n",
    "        points = np.stack([X.flatten(), Y.flatten(), Z.flatten()], axis=-1)\n",
    "        inside = mesh.contains(points)\n",
    "        inside_grid = inside.reshape(X.shape)\n",
    "        X_masked = np.where(inside_grid, X, np.nan)\n",
    "        Y_masked = np.where(inside_grid, Y, np.nan)\n",
    "        Z_masked = np.where(inside_grid, Z, np.nan)\n",
    "        \n",
    "        fig.add_trace(go.Surface(x=X_masked, y=Y_masked, z=Z_masked,\n",
    "                                 opacity=0.5, colorscale=[[0, 'blue'], [1, 'blue']]))\n",
    "    \n",
    "    fig.update_layout(scene=dict(aspectmode='data'))\n",
    "    fig.show()\n",
    "\n",
    "visualize_floors(vertices, faces, floor_levels)\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Assemble Base Geometry (Processed Floors and Walls)\n",
    "# ----------------------------\n",
    "geometries_list = []\n",
    "if floor_mesh_new is not None:\n",
    "    geometries_list.append(floor_mesh_new)\n",
    "if wall_mesh_new is not None:\n",
    "    geometries_list.append(wall_mesh_new)\n",
    "\n",
    "if geometries_list:\n",
    "    base_geometry = trimesh.util.concatenate(geometries_list)\n",
    "    print(\"Base geometry has {} vertices and {} faces.\".format(len(base_geometry.vertices), len(base_geometry.faces)))\n",
    "else:\n",
    "    base_geometry = None\n",
    "    print(\"No base geometry created.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 9. Create Additional Floors (if needed)\n",
    "# ----------------------------\n",
    "added_floors_list = []\n",
    "if additional_floors > 0 and floor_mesh_new is not None:\n",
    "    # Compute the floor height from the original bounding box and total floors\n",
    "    floor_height = (np.max(vertices[:, 2]) - np.min(vertices[:, 2])) / total_floors\n",
    "    for i in range(additional_floors):\n",
    "        new_floor_vertices = np.copy(floor_mesh_new.vertices)\n",
    "        new_floor_vertices[:, 2] += (i + 1) * floor_height\n",
    "        new_floors_mesh = trimesh.Trimesh(vertices=new_floor_vertices, faces=floor_mesh_new.faces)\n",
    "        added_floors_list.append(new_floors_mesh)\n",
    "\n",
    "# ----------------------------\n",
    "# 10. Combine Base Geometry and Additional Floors for Final Export\n",
    "# ----------------------------\n",
    "all_geometries = []\n",
    "if base_geometry is not None:\n",
    "    all_geometries.append(base_geometry)\n",
    "if added_floors_list:\n",
    "    all_geometries.extend(added_floors_list)\n",
    "\n",
    "if all_geometries:\n",
    "    final_geometry = trimesh.util.concatenate(all_geometries)\n",
    "    print(\"Final geometry has {} vertices and {} faces.\".format(len(final_geometry.vertices), len(final_geometry.faces)))\n",
    "else:\n",
    "    final_geometry = None\n",
    "    print(\"No final geometry created.\")\n",
    "\n",
    "# Export full geometry (base + added floors)\n",
    "if final_geometry is not None:\n",
    "    export_path_full = r\"..\\Reference Files\\Final_Model.obj\"  # Define the export path\n",
    "    final_geometry.export(export_path_full)\n",
    "    print(f\"Final model (including all floors) exported to {export_path_full}\")\n",
    "\n",
    "# Export only added floors (if any)\n",
    "if added_floors_list:\n",
    "    added_floors_geometry = trimesh.util.concatenate(added_floors_list)\n",
    "    export_path_added = r\"..\\Reference Files\\Added_Floors2.obj\"\n",
    "    added_floors_geometry.export(export_path_added)\n",
    "    print(f\"Added floors model exported to {export_path_added}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom surface has 7 outer boundary edges.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 11. Extract and visualize only the bottom surface's outer edges using Open3D\n",
    "# ----------------------------\n",
    "import networkx as nx\n",
    "\n",
    "if final_geometry is not None:\n",
    "    # Get all vertices from the final geometry\n",
    "    vertices_final = final_geometry.vertices\n",
    "    # Determine the minimum Z (bottom) value\n",
    "    bottom_z = vertices_final[:, 2].min()\n",
    "    tol = 1e-3  # Tolerance for comparing Z values\n",
    "\n",
    "    # Identify faces whose centroid is at the bottom\n",
    "    bottom_face_indices = []\n",
    "    for i, face in enumerate(final_geometry.faces):\n",
    "        centroid = vertices_final[face].mean(axis=0)\n",
    "        if abs(centroid[2] - bottom_z) < tol:\n",
    "            bottom_face_indices.append(i)\n",
    "\n",
    "    if not bottom_face_indices:\n",
    "        print(\"No bottom surface faces found.\")\n",
    "    else:\n",
    "        # Create a new trimesh object for the bottom surface\n",
    "        bottom_mesh = trimesh.Trimesh(vertices=vertices_final,\n",
    "                                      faces=final_geometry.faces[bottom_face_indices],\n",
    "                                      process=True)\n",
    "        # Extract boundary edges from the bottom mesh.\n",
    "        # These are the edges that are only shared by one face.\n",
    "        edges_sorted = np.sort(bottom_mesh.edges, axis=1)\n",
    "        unique_edges, counts = np.unique(edges_sorted, axis=0, return_counts=True)\n",
    "        boundary_edges = unique_edges[counts == 1]\n",
    "        if len(boundary_edges) == 0:\n",
    "            print(\"No boundary edges found on the bottom surface.\")\n",
    "        else:\n",
    "            # Build a graph of boundary edges to group them into connected loops.\n",
    "            G = nx.Graph()\n",
    "            for edge in boundary_edges:\n",
    "                G.add_edge(edge[0], edge[1])\n",
    "            components = list(nx.connected_components(G))\n",
    "            # Select the largest component (assuming that represents the outer boundary)\n",
    "            largest_component = max(components, key=len)\n",
    "            # Filter boundary edges to keep only those whose both vertices belong to the largest component.\n",
    "            outer_edges = [edge for edge in boundary_edges \n",
    "                           if edge[0] in largest_component and edge[1] in largest_component]\n",
    "            outer_edges = np.array(outer_edges)\n",
    "            \n",
    "            print(f\"Bottom surface has {len(outer_edges)} outer boundary edges.\")\n",
    "\n",
    "            # Visualize the outer boundary using Open3D\n",
    "            line_set = o3d.geometry.LineSet()\n",
    "            line_set.points = o3d.utility.Vector3dVector(bottom_mesh.vertices)\n",
    "            line_set.lines = o3d.utility.Vector2iVector(outer_edges)\n",
    "            # Set a uniform color (blue)\n",
    "            colors = np.tile([0, 0, 1], (len(outer_edges), 1))\n",
    "            line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "            \n",
    "            o3d.visualization.draw_geometries([line_set])\n",
    "else:\n",
    "    print(\"Final geometry is None; nothing to process for bottom surface visualization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString, Polygon\n",
    "import math\n",
    "\n",
    "def is_rectangle(polygon, tol=1e-7):\n",
    "    \"\"\"Check if polygon is a rectangle by comparing with its bounding box.\"\"\"\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    bounding_rect = Polygon([(minx, miny), (minx, maxy), (maxx, maxy), (maxx, miny)])\n",
    "    return polygon.equals_exact(bounding_rect, tolerance=tol)\n",
    "\n",
    "def find_concave_corner_coords(poly):\n",
    "    \"\"\"\n",
    "    Find coordinates of a concave corner in an orth polygon.\n",
    "    Returns (x, y, direction) or None if none found.\n",
    "    'direction' could be 'horizontal' or 'vertical' for the line to shoot.\n",
    "    \"\"\"\n",
    "    coords = list(poly.exterior.coords)\n",
    "    # coords is closed (first = last), so we can iterate from 0 to len-2\n",
    "    for i in range(1, len(coords)-1):\n",
    "        prev_pt = coords[i-1]\n",
    "        curr_pt = coords[i]\n",
    "        next_pt = coords[i+1]\n",
    "        \n",
    "        # Vectors\n",
    "        v1 = (curr_pt[0] - prev_pt[0], curr_pt[1] - prev_pt[1])\n",
    "        v2 = (next_pt[0] - curr_pt[0], next_pt[1] - curr_pt[1])\n",
    "        \n",
    "        # Check orth: v1 or v2 is horizontal/vertical\n",
    "        # Then check if interior angle is 270° => cross or dot product sign\n",
    "        # A simpler approach: check if the direction of v1 -> v2 is an inward turn\n",
    "        # for an orth polygon.\n",
    "        \n",
    "        # We can check the sign of cross product:\n",
    "        cross = v1[0]*v2[1] - v1[1]*v2[0]\n",
    "        # For an orth polygon, cross != 0 means a 90° turn. The sign indicates left or right turn.\n",
    "        \n",
    "        # We also check if it's \"concave\" by verifying that the interior angle > 180°.\n",
    "        # For a polygon in standard orientation, a 'right turn' might indicate concavity if edges are oriented CCW, etc.\n",
    "        # We'll do a naive check: if cross < 0 => might be concave corner (assuming polygon is CCW).\n",
    "        \n",
    "        if cross < 0:\n",
    "            # We found a candidate concave corner\n",
    "            # Decide if we shoot horizontally or vertically from here.\n",
    "            # We can see if v1 is vertical => then v2 is horizontal, or vice versa.\n",
    "            # We'll pick the direction that is \"straight out\" from the corner.\n",
    "            # This can get tricky, but let's do a simplified approach:\n",
    "            \n",
    "            # If v1 is vertical, v2 is horizontal => shoot horizontally\n",
    "            # If v1 is horizontal, v2 is vertical => shoot vertically\n",
    "            # If the polygon is consistently CCW, you can pick a consistent approach.\n",
    "            \n",
    "            v1_h = (abs(v1[1]) < 1e-9)\n",
    "            v2_h = (abs(v2[1]) < 1e-9)\n",
    "            \n",
    "            if v1_h and not v2_h:\n",
    "                direction = 'vertical'\n",
    "            elif not v1_h and v2_h:\n",
    "                direction = 'horizontal'\n",
    "            else:\n",
    "                # If it's ambiguous or we have a corner that doesn't match, skip\n",
    "                continue\n",
    "            \n",
    "            return (curr_pt[0], curr_pt[1], direction)\n",
    "    return None\n",
    "\n",
    "def shoot_line(poly, corner):\n",
    "    \"\"\"\n",
    "    Shoot a horizontal or vertical line from 'corner' across 'poly'.\n",
    "    Return a shapely LineString that extends fully across the polygon.\n",
    "    corner = (x, y, direction).\n",
    "    \"\"\"\n",
    "    x, y, direction = corner\n",
    "    minx, miny, maxx, maxy = poly.bounds\n",
    "    if direction == 'horizontal':\n",
    "        # y is fixed, extend from minx to maxx\n",
    "        return LineString([(minx-1, y), (maxx+1, y)])\n",
    "    else:\n",
    "        # direction == 'vertical'\n",
    "        return LineString([(x, miny-1), (x, maxy+1)])\n",
    "\n",
    "def decompose_into_rectangles(poly, rectangles=None):\n",
    "    \"\"\"\n",
    "    Recursively decompose an orth polygon into rectangles using corner-cutting.\n",
    "    \"\"\"\n",
    "    if rectangles is None:\n",
    "        rectangles = []\n",
    "    \n",
    "    poly = poly.buffer(0)  # fix any slight invalidities\n",
    "    \n",
    "    # Base case: if already a rectangle, add it and return\n",
    "    if is_rectangle(poly):\n",
    "        rectangles.append(poly)\n",
    "        return rectangles\n",
    "    \n",
    "    # Otherwise, find a concave corner\n",
    "    corner = find_concave_corner_coords(poly)\n",
    "    if corner is None:\n",
    "        # No concave corner found, either it's a rectangle or we can't proceed\n",
    "        rectangles.append(poly)\n",
    "        return rectangles\n",
    "    \n",
    "    # Shoot line\n",
    "    cut_line = shoot_line(poly, corner)\n",
    "    # Convert line to a thin polygon to ensure robust intersection\n",
    "    cut_poly = cut_line.buffer(1e-9)\n",
    "    \n",
    "    # Subdivide\n",
    "    poly1 = poly.intersection(cut_poly)\n",
    "    poly2 = poly.difference(poly1)\n",
    "    \n",
    "    # Recurse on each sub-polygon (which might itself be MultiPolygon)\n",
    "    def recurse_subparts(sub):\n",
    "        if sub.is_empty:\n",
    "            return\n",
    "        if sub.geom_type == 'Polygon':\n",
    "            decompose_into_rectangles(sub, rectangles)\n",
    "        elif sub.geom_type == 'MultiPolygon':\n",
    "            for p in sub.geoms:\n",
    "                decompose_into_rectangles(p, rectangles)\n",
    "    \n",
    "    recurse_subparts(poly1)\n",
    "    recurse_subparts(poly2)\n",
    "    \n",
    "    return rectangles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRecursionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m poly = poly.buffer(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# fix geometry if needed\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Decompose\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m rects = \u001b[43mdecompose_into_rectangles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(rects)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rectangles in the bottom surface.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Visualization (matplotlib)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m    118\u001b[39m             decompose_into_rectangles(p, rectangles)\n\u001b[32m    120\u001b[39m recurse_subparts(poly1)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[43mrecurse_subparts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rectangles\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mdecompose_into_rectangles.<locals>.recurse_subparts\u001b[39m\u001b[34m(sub)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[43mdecompose_into_rectangles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrectangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mMultiPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sub.geoms:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m    118\u001b[39m             decompose_into_rectangles(p, rectangles)\n\u001b[32m    120\u001b[39m recurse_subparts(poly1)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[43mrecurse_subparts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rectangles\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mdecompose_into_rectangles.<locals>.recurse_subparts\u001b[39m\u001b[34m(sub)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[43mdecompose_into_rectangles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrectangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mMultiPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sub.geoms:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m    118\u001b[39m             decompose_into_rectangles(p, rectangles)\n\u001b[32m    120\u001b[39m recurse_subparts(poly1)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[43mrecurse_subparts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rectangles\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 118\u001b[39m, in \u001b[36mdecompose_into_rectangles.<locals>.recurse_subparts\u001b[39m\u001b[34m(sub)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mMultiPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sub.geoms:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m         \u001b[43mdecompose_into_rectangles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrectangles\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m    117\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sub.geoms:\n\u001b[32m    118\u001b[39m             decompose_into_rectangles(p, rectangles)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43mrecurse_subparts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m recurse_subparts(poly2)\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rectangles\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mdecompose_into_rectangles.<locals>.recurse_subparts\u001b[39m\u001b[34m(sub)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[43mdecompose_into_rectangles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrectangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mMultiPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sub.geoms:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m    117\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sub.geoms:\n\u001b[32m    118\u001b[39m             decompose_into_rectangles(p, rectangles)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43mrecurse_subparts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m recurse_subparts(poly2)\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rectangles\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mdecompose_into_rectangles.<locals>.recurse_subparts\u001b[39m\u001b[34m(sub)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[43mdecompose_into_rectangles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrectangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mMultiPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sub.geoms:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m    118\u001b[39m             decompose_into_rectangles(p, rectangles)\n\u001b[32m    120\u001b[39m recurse_subparts(poly1)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[43mrecurse_subparts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rectangles\n",
      "    \u001b[31m[... skipping similar frames: decompose_into_rectangles.<locals>.recurse_subparts at line 115 (1 times)]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m    118\u001b[39m             decompose_into_rectangles(p, rectangles)\n\u001b[32m    120\u001b[39m recurse_subparts(poly1)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[43mrecurse_subparts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rectangles\n",
      "    \u001b[31m[... skipping similar frames: decompose_into_rectangles.<locals>.recurse_subparts at line 115 (1475 times), decompose_into_rectangles at line 120 (885 times), decompose_into_rectangles at line 121 (589 times)]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m    118\u001b[39m             decompose_into_rectangles(p, rectangles)\n\u001b[32m    120\u001b[39m recurse_subparts(poly1)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[43mrecurse_subparts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rectangles\n",
      "    \u001b[31m[... skipping similar frames: decompose_into_rectangles.<locals>.recurse_subparts at line 115 (4 times), decompose_into_rectangles at line 120 (3 times)]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m    117\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sub.geoms:\n\u001b[32m    118\u001b[39m             decompose_into_rectangles(p, rectangles)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43mrecurse_subparts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoly1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m recurse_subparts(poly2)\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rectangles\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mdecompose_into_rectangles.<locals>.recurse_subparts\u001b[39m\u001b[34m(sub)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[43mdecompose_into_rectangles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrectangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sub.geom_type == \u001b[33m'\u001b[39m\u001b[33mMultiPolygon\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sub.geoms:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mdecompose_into_rectangles\u001b[39m\u001b[34m(poly, rectangles)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rectangles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     85\u001b[39m     rectangles = []\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m poly = \u001b[43mpoly\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# fix any slight invalidities\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Base case: if already a rectangle, add it and return\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_rectangle(poly):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\IaaC\\RESEARCH\\GITHUB\\Octopusie\\.venv\\Lib\\site-packages\\shapely\\geometry\\base.py:545\u001b[39m, in \u001b[36mBaseGeometry.buffer\u001b[39m\u001b[34m(self, distance, quad_segs, cap_style, join_style, mitre_limit, single_sided, **kwargs)\u001b[39m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(distance).all():\n\u001b[32m    543\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mbuffer distance must be finite\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshapely\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquad_segs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquad_segs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcap_style\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcap_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin_style\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmitre_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmitre_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43msingle_sided\u001b[49m\u001b[43m=\u001b[49m\u001b[43msingle_sided\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\IaaC\\RESEARCH\\GITHUB\\Octopusie\\.venv\\Lib\\site-packages\\shapely\\decorators.py:77\u001b[39m, in \u001b[36mmultithreading_enabled.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[32m     76\u001b[39m         arr.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\IaaC\\RESEARCH\\GITHUB\\Octopusie\\.venv\\Lib\\site-packages\\shapely\\constructive.py:167\u001b[39m, in \u001b[36mbuffer\u001b[39m\u001b[34m(geometry, distance, quad_segs, cap_style, join_style, mitre_limit, single_sided, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[33;03mComputes the buffer of a geometry for positive and negative buffer distance.\u001b[39;00m\n\u001b[32m     98\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    164\u001b[39m \u001b[33;03mTrue\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cap_style, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     cap_style = \u001b[43mBufferCapStyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcap_style\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(join_style, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    169\u001b[39m     join_style = BufferJoinStyle.get_value(join_style)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\IaaC\\RESEARCH\\GITHUB\\Octopusie\\.venv\\Lib\\site-packages\\shapely\\_enum.py:16\u001b[39m, in \u001b[36mParamEnum.get_value\u001b[39m\u001b[34m(cls, item)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Validate incoming item and raise a ValueError with valid options if not present.\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m.value\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m     18\u001b[39m     valid_options = {e.name \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m}\n",
      "\u001b[31mRecursionError\u001b[39m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import trimesh\n",
    "import shapely\n",
    "from shapely.geometry import Polygon, LineString\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppose you already have:\n",
    "#   vertices_final: Nx3 array (X, Y, Z)\n",
    "#   outer_edges: Mx2 array of vertex indices\n",
    "# Convert to 2D polygon:\n",
    "boundary_2d = order_boundary_edges(vertices_final[:, :2], outer_edges)\n",
    "poly = Polygon(boundary_2d)\n",
    "poly = poly.buffer(0)  # fix geometry if needed\n",
    "\n",
    "# Decompose\n",
    "rects = decompose_into_rectangles(poly)\n",
    "\n",
    "print(f\"Found {len(rects)} rectangles in the bottom surface.\")\n",
    "\n",
    "# Visualization (matplotlib)\n",
    "fig, ax = plt.subplots()\n",
    "for r in rects:\n",
    "    x,y = r.exterior.xy\n",
    "    ax.fill(x, y, alpha=0.5)\n",
    "    \n",
    "# Also plot the original boundary in black\n",
    "bx, by = poly.exterior.xy\n",
    "ax.plot(bx, by, 'k-')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------\n",
    "# 1. Load the OBJ mesh and compute vertex normals.\n",
    "# --------------------------\n",
    "mesh = o3d.io.read_triangle_mesh(r\"..\\Reference Files\\Final_Model.obj\")\n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "# --------------------------\n",
    "# 2. Extract nodes (vertices) from the mesh.\n",
    "# --------------------------\n",
    "vertices = np.asarray(mesh.vertices)\n",
    "\n",
    "# Create a point cloud for nodes and color them red.\n",
    "nodes_pc = o3d.geometry.PointCloud()\n",
    "nodes_pc.points = o3d.utility.Vector3dVector(vertices)\n",
    "nodes_pc.paint_uniform_color([1.0, 0.0, 0.0])  # red\n",
    "\n",
    "# --------------------------\n",
    "# 3. Extract edges from the mesh using triangle connectivity.\n",
    "#    Also record which triangles share each edge.\n",
    "# --------------------------\n",
    "triangles = np.asarray(mesh.triangles)\n",
    "edge_to_triangles = {}  # key: edge (sorted tuple), value: list of triangle indices\n",
    "for t, tri in enumerate(triangles):\n",
    "    # For each triangle, add all three edges.\n",
    "    for i in range(3):\n",
    "        for j in range(i + 1, 3):\n",
    "            edge = tuple(sorted((tri[i], tri[j])))\n",
    "            edge_to_triangles.setdefault(edge, []).append(t)\n",
    "\n",
    "# --------------------------\n",
    "# 4. Filter edges to omit any coplanar diagonal (internal) connections.\n",
    "#    For each edge that is shared by exactly two triangles:\n",
    "#      - If the union of the vertices of the two triangles has 4 unique indices\n",
    "#        (i.e. they form a quad) and the two triangles are nearly coplanar,\n",
    "#        then omit that edge.\n",
    "# --------------------------\n",
    "def compute_triangle_normal(tri_indices):\n",
    "    pts = vertices[list(tri_indices)]\n",
    "    normal = np.cross(pts[1] - pts[0], pts[2] - pts[0])\n",
    "    norm = np.linalg.norm(normal)\n",
    "    if norm != 0:\n",
    "        normal /= norm\n",
    "    return normal\n",
    "\n",
    "filtered_edges = []\n",
    "for edge, tri_indices in edge_to_triangles.items():\n",
    "    if len(tri_indices) < 2:\n",
    "        # Boundary edge – always keep it.\n",
    "        filtered_edges.append(edge)\n",
    "    elif len(tri_indices) == 2:\n",
    "        t1, t2 = tri_indices\n",
    "        tri1 = triangles[t1]\n",
    "        tri2 = triangles[t2]\n",
    "        # Form the union of vertices from both triangles.\n",
    "        union_vertices = set(tri1.tolist() + tri2.tolist())\n",
    "        if len(union_vertices) == 4:\n",
    "            # Two triangles form a quadrilateral – check if they are nearly coplanar.\n",
    "            n1 = compute_triangle_normal(tri1)\n",
    "            n2 = compute_triangle_normal(tri2)\n",
    "            # If the dot product is close to 1, the triangles are coplanar.\n",
    "            if np.dot(n1, n2) > 0.99:\n",
    "                # Omit this edge as it is a diagonal in a coplanar quad.\n",
    "                continue\n",
    "            else:\n",
    "                filtered_edges.append(edge)\n",
    "        else:\n",
    "            filtered_edges.append(edge)\n",
    "    else:\n",
    "        # If more than 2 triangles share the edge (rare), keep it.\n",
    "        filtered_edges.append(edge)\n",
    "\n",
    "filtered_edges = np.array(filtered_edges)\n",
    "\n",
    "# --------------------------\n",
    "# 5. Visualize the nodes (vertices) and the filtered edges.\n",
    "# --------------------------\n",
    "line_set = o3d.geometry.LineSet()\n",
    "line_set.points = o3d.utility.Vector3dVector(vertices)\n",
    "line_set.lines = o3d.utility.Vector2iVector(filtered_edges)\n",
    "line_set.colors = o3d.utility.Vector3dVector([[0.0, 1.0, 0.0] for _ in range(len(filtered_edges))])  # green edges\n",
    "\n",
    "o3d.visualization.draw_geometries([nodes_pc, line_set],\n",
    "                                  window_name=\"Graph: Nodes and Edges without Diagonals\",\n",
    "                                  width=800, height=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 64, 64, 64)\n",
      "Dataset saved to: cuboid_dataset\\cuboids_dataset.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Parameters for the dataset\n",
    "num_samples = 1000  # Generate 1000 cuboids\n",
    "volume_shape = (64, 64, 64)  # Each sample is a 64x64x64 voxel grid\n",
    "min_dim = 10  # Minimum cuboid edge length\n",
    "max_dim = 40  # Maximum cuboid edge length\n",
    "\n",
    "# Create an empty list to store the samples\n",
    "dataset = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Create an empty volume\n",
    "    volume = np.zeros(volume_shape, dtype=np.uint8)\n",
    "    \n",
    "    # Randomly choose dimensions for the cuboid along each axis\n",
    "    cuboid_dim = [np.random.randint(min_dim, max_dim) for _ in range(3)]\n",
    "    \n",
    "    # Ensure the cuboid fits entirely in the volume by choosing a valid starting point\n",
    "    start = [np.random.randint(0, volume_shape[d] - cuboid_dim[d] + 1) for d in range(3)]\n",
    "    \n",
    "    # Fill the cuboid region with ones\n",
    "    volume[start[0]:start[0] + cuboid_dim[0],\n",
    "           start[1]:start[1] + cuboid_dim[1],\n",
    "           start[2]:start[2] + cuboid_dim[2]] = 1\n",
    "    \n",
    "    dataset.append(volume)\n",
    "\n",
    "# Convert the list to a numpy array: shape (num_samples, 64, 64, 64)\n",
    "dataset = np.array(dataset)\n",
    "print(\"Dataset shape:\", dataset.shape)\n",
    "\n",
    "# Optionally, save the dataset to disk (e.g., as a .npz file)\n",
    "output_dir = \"cuboid_dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "np.savez_compressed(os.path.join(output_dir, \"cuboids_dataset.npz\"), dataset=dataset)\n",
    "\n",
    "print(\"Dataset saved to:\", os.path.join(output_dir, \"cuboids_dataset.npz\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
